{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Treino e Teste, Validação Cruzada e Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Introdução\n",
    "\n",
    "Trabalharemos com uma base de dados sobre [preços de imóveis em Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). \n",
    "\n",
    "Essa base possui um número grande de atributos descritos a seguir.\n",
    "\n",
    "### Variável alvo\n",
    "\n",
    "* SalePrice: O preço do imóvel em dólar. \n",
    "\n",
    "\n",
    "### Atributos\n",
    "\n",
    "<table>\n",
    "  <tbody>    \n",
    "    <tr valign=\"top\">\n",
    "      <td valign=\"top\">\n",
    "        <ul>\n",
    "          <li>MoSold: Mês da Venda</li>\n",
    "          <li>YrSold: Ano da Venda</li><br>\n",
    "          \n",
    "          <li>SaleType: Tipo da venda</li>\n",
    "          <li>SaleCondition: Condição da venda</li><br>\n",
    "\n",
    "          <li>MSSubClass: O tipo de construção</li>\n",
    "          <li>MSZoning: Classificação da região</li><br>\n",
    "\n",
    "          <li>Neighborhood: Bairro</li>\n",
    "          <li>Street: Tipo de via de acesso</li>\n",
    "          <li>Alley: Tipo de via atrás da construção</li><br>\n",
    "\n",
    "          <li>LotArea: Área em pés ao quadrado</li>\n",
    "          <li>LotConfig: Configuração do loteamento</li>\n",
    "          <li>LotFrontage: Comprimento da rua de acesso</li>\n",
    "          <li>LotShape: Forma geral da propriedade</li><br>\n",
    "\n",
    "          <li>LandSlope: Inclinação da propriedade</li>\n",
    "          <li>LandContour: Contorno plano</li><br>\n",
    "\n",
    "          <li>YearBuilt: Data original da construção</li>\n",
    "          <li>YearRemodAdd: Data de reforma</li>\n",
    "          <li>OverallQual: Material e qualidade de acabamento</li>\n",
    "          <li>OverallCond: Nota de condições gerais</li><br>\n",
    "\n",
    "          <li>Utilities: Tipo de serviços encontrados</li>\n",
    "          <li>Foundation: Tipo de fundação</li>\n",
    "          <li>Functional: Nota da funcionalidade</li><br>\n",
    "\n",
    "          <li>BldgType: Tipo de moradia</li>\n",
    "          <li>HouseStyle: Estilo de moradia</li><br>\n",
    "          \n",
    "          <li>1stFlrSF: Pés quadrados do primeiro andar</li>\n",
    "          <li>2ndFlrSF: Pés quadrados do segundo andar</li>\n",
    "          <li>LowQualFinSF: Acabamento de baixa qualidade por metro quadrado</li>\n",
    "          <li>GrLivArea: Acima da média qualidade da área útil</li>\n",
    "          <li>TotRmsAbvGrd: Total de quartos acima do solo</li><br>\n",
    "\n",
    "          <li>Condition1: Proximidade a rodovia ou ferrovia</li>\n",
    "          <li>Condition2: Proximidade a uma segunda rodovia ou fererovia</li><br>\n",
    "          \n",
    "          <li>RoofStyle: Tipo de telhado</li>\n",
    "          <li>RoofMatl: Material do telhado</li><br>\n",
    "\n",
    "          <li>ExterQual: Qualidade do material externo</li>\n",
    "          <li>ExterCond: Condição atual do material externo</li>\n",
    "          <li>Exterior1st: Cobertura exterior do imóvel</li>\n",
    "          <li>Exterior2nd: Segundo tipo de cobertura exterior</li><br><br>\n",
    "          \n",
    "        </ul>\n",
    "      </td>\n",
    "      \n",
    "      <td valign=\"top\">\n",
    "        <ul>\n",
    "          <li>MasVnrType: Masonry veneer type</li>\n",
    "          <li>MasVnrArea: Masonry veneer area in square feet</li><br>\n",
    "          \n",
    "          <li>WoodDeckSF: Wood deck area in square feet</li>\n",
    "          <li>OpenPorchSF: Open porch area in square feet</li>\n",
    "          <li>EnclosedPorch: Enclosed porch area in square feet</li>\n",
    "          <li>3SsnPorch: Three season porch area in square feet</li>\n",
    "          <li>ScreenPorch: Screen porch area in square feet</li><br>\n",
    "\n",
    "          <li>PoolArea: Pool area in square feet</li>\n",
    "          <li>PoolQC: Pool quality</li>\n",
    "          <li>Fence: Fence quality</li>\n",
    "          <li>PavedDrive: Paved driveway</li><br>\n",
    "\n",
    "          <li>GarageType: Garage location</li>\n",
    "          <li>GarageYrBlt: Year garage was built</li>\n",
    "          <li>GarageFinish: Interior finish of the garage</li>\n",
    "          <li>GarageCars: Size of garage in car capacity</li>\n",
    "          <li>GarageArea: Size of garage in square feet</li>\n",
    "          <li>GarageQual: Garage quality</li>\n",
    "          <li>GarageCond: Garage condition</li><br>\n",
    "\n",
    "          <li>Heating: Type of heating</li>\n",
    "          <li>HeatingQC: Heating quality and condition</li>\n",
    "          <li>CentralAir: Central air conditioning</li>\n",
    "          <li>Electrical: Electrical system</li><br>\n",
    "          \n",
    "          <li>FullBath: Full bathrooms above grade</li>\n",
    "          <li>HalfBath: Half baths above grade</li><br>\n",
    "          \n",
    "          <li>BedroomAbvGr: Number of bedrooms above basement level</li><br>\n",
    "          \n",
    "          <li>KitchenAbvGr: Number of kitchens</li>\n",
    "          <li>KitchenQual: Kitchen quality</li><br>\n",
    "          \n",
    "          <li>Fireplaces: Number of fireplaces</li>\n",
    "          <li>FireplaceQu: Fireplace quality</li><br>\n",
    "          \n",
    "          <li>MiscFeature: Miscellaneous feature not covered in other categories</li>\n",
    "          <li>MiscVal: Value of miscellaneous feature</li><br>\n",
    "          \n",
    "          <li>BsmtQual: Height of the basement</li>\n",
    "          <li>BsmtCond: General condition of the basement</li>\n",
    "          <li>BsmtExposure: Walkout or garden level basement walls</li>\n",
    "          <li>BsmtFinType1: Quality of basement finished area</li>\n",
    "          <li>BsmtFinSF1: Type 1 finished square feet</li>\n",
    "          <li>BsmtFinType2: Quality of second finished area (if present)</li>\n",
    "          <li>BsmtFinSF2: Type 2 finished square feet</li>\n",
    "          <li>BsmtUnfSF: Unfinished square feet of basement area</li>\n",
    "          <li>BsmtFullBath: Basement full bathrooms</li>\n",
    "          <li>BsmtHalfBath: Basement half bathrooms</li>\n",
    "          <li>TotalBsmtSF: Total square feet of basement area</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "    </tr>\n",
    "    \n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 1\n",
    "\n",
    "* Importe os dados usando Pandas e examine a dimensão da base. Existem 79 atributos mais o preditor, o preço de venda (`SalePrice`). \n",
    "* Existem três diferentes tipos: integers (`int64`), floats (`float64`), e strings (`object`, categóricos). Examine quantos existem de cada tipo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1379, 80)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = 'data/Ames_Housing_Sales.csv'\n",
    "data = pd.read_csv(filepath, sep=',')\n",
    "\n",
    "# imprima a dimensão da base\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>8</td>\n",
       "      <td>856.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>756.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>9</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch Alley  BedroomAbvGr BldgType BsmtCond  \\\n",
       "0     856.0     854.0        0.0  None             3     1Fam       TA   \n",
       "1    1262.0       0.0        0.0  None             3     1Fam       TA   \n",
       "2     920.0     866.0        0.0  None             3     1Fam       TA   \n",
       "3     961.0     756.0        0.0  None             3     1Fam       Gd   \n",
       "4    1145.0    1053.0        0.0  None             4     1Fam       TA   \n",
       "\n",
       "  BsmtExposure  BsmtFinSF1  BsmtFinSF2    ...    ScreenPorch Street  \\\n",
       "0           No       706.0         0.0    ...            0.0   Pave   \n",
       "1           Gd       978.0         0.0    ...            0.0   Pave   \n",
       "2           Mn       486.0         0.0    ...            0.0   Pave   \n",
       "3           No       216.0         0.0    ...            0.0   Pave   \n",
       "4           Av       655.0         0.0    ...            0.0   Pave   \n",
       "\n",
       "   TotRmsAbvGrd  TotalBsmtSF Utilities  WoodDeckSF YearBuilt YearRemodAdd  \\\n",
       "0             8        856.0    AllPub         0.0      2003         2003   \n",
       "1             6       1262.0    AllPub       298.0      1976         1976   \n",
       "2             6        920.0    AllPub         0.0      2001         2002   \n",
       "3             7        756.0    AllPub         0.0      1915         1970   \n",
       "4             9       1145.0    AllPub       192.0      2000         2000   \n",
       "\n",
       "  YrSold SalePrice  \n",
       "0   2008  208500.0  \n",
       "1   2007  181500.0  \n",
       "2   2008  223500.0  \n",
       "3   2006  140000.0  \n",
       "4   2008  250000.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vizualização da Data\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     43\n",
       "float64    21\n",
       "int64      16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use o método value_counts() no atributo dtypes\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 2\n",
    "\n",
    "Como discutido em aula, um desafio da área de Aprendizado de Máquina, principalmente quando lidamos com dados com muitos atributos, é garantir que cada coluna seja codificada corretamente.\n",
    "\n",
    "Isso é particularmente verdade com atributos que são ordinais e categóricos sem ordem. Os categóricos sem ordem devem ser codificados de forma binária através do procedimento One-hot-encoding, porém isso costuma aumentar significativamente o total de atributos e cria atributos altamente correlacionados.\n",
    "\n",
    "Determine o total de atributos de nossa base se todos os atributos categóricos fossem convertidos para binários. Lembre-se que para um atributo categórico com `n` valores, precisamos apenas de `n-1` atributos para representá-lo de forma binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "       'BsmtFinType2', 'BsmtQual', 'CentralAir', 'Condition1', 'Condition2',\n",
       "       'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd',\n",
       "       'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond',\n",
       "       'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC',\n",
       "       'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig',\n",
       "       'LotShape', 'MSZoning', 'MasVnrType', 'MiscFeature', 'Neighborhood',\n",
       "       'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition',\n",
       "       'SaleType', 'Street', 'Utilities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecione apenas os tipos object\n",
    "mask = data.dtypes == np.object\n",
    "categorical_cols = data.columns[mask]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utilities         2\n",
       "Street            2\n",
       "CentralAir        2\n",
       "PavedDrive        3\n",
       "LandSlope         3\n",
       "GarageFinish      3\n",
       "Alley             3\n",
       "PoolQC            4\n",
       "ExterCond         4\n",
       "ExterQual         4\n",
       "MasVnrType        4\n",
       "LotShape          4\n",
       "BsmtCond          4\n",
       "LandContour       4\n",
       "KitchenQual       4\n",
       "HeatingQC         5\n",
       "BldgType          5\n",
       "MiscFeature       5\n",
       "MSZoning          5\n",
       "LotConfig         5\n",
       "BsmtQual          5\n",
       "GarageQual        5\n",
       "GarageCond        5\n",
       "Fence             5\n",
       "Electrical        5\n",
       "BsmtExposure      5\n",
       "GarageType        6\n",
       "Heating           6\n",
       "BsmtFinType1      6\n",
       "SaleCondition     6\n",
       "RoofStyle         6\n",
       "Foundation        6\n",
       "FireplaceQu       6\n",
       "BsmtFinType2      7\n",
       "Functional        7\n",
       "Condition2        8\n",
       "RoofMatl          8\n",
       "HouseStyle        8\n",
       "Condition1        9\n",
       "SaleType          9\n",
       "Exterior1st      14\n",
       "Exterior2nd      16\n",
       "Neighborhood     25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine quantos atributos seriam criados\n",
    "# Dica: aplique (apply) o método nunique no dataframe nas colunas categorical_cols\n",
    "# opcionalmente ordene os valores utilizando sort_values\n",
    "# verifique a saída\n",
    "num_ohc_cols = data[categorical_cols].apply(pd.Series.nunique, axis=0)\n",
    "num_ohc_cols.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elimine do resultado toda coluna com apenas 1 valor categórico\n",
    "num_ohc_cols = num_ohc_cols[num_ohc_cols.values != 1]\n",
    "# Subtraia em um os valores\n",
    "num_ohc_cols = num_ohc_cols - 1\n",
    "# Faça a soma dos valores, a quantidade de novos atributos é significativo!\n",
    "num_ohc_cols.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 3\n",
    "\n",
    "Vamos criar uma nova base de dados onde todos os atributos categóricos são binarizados pelo procedimento one-hot-encoding. Podemos testar como isso afeta o modelo de regressão.\n",
    "\n",
    "* Usando o método `.copy()`  do dataframe, crie uma cópia para aplicar o one-hot encoding\n",
    "* Nesse novo dataframe, aplique o LabelEncoder seguido do OneHotEncoder para gerar os novos atributos. Não se esqueça de aplicar o método `.drop()` nas colunas originais.\n",
    "* Para a base original, aplique `.drop()` para todos os atributos categóricos.\n",
    "\n",
    "Para gerar o one-hot-encoding das variáveis, primeiro aplicaremos o `LabelEncoder` do Scikit-Learn para transformar as strings em números de ids. Após esse procedimento, podemos aplicar o `OneHotEncoder` para gerar os novos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Copia dos dados\n",
    "data_ohc = data.copy()\n",
    "\n",
    "# Vamos codificar\n",
    "le = LabelEncoder()\n",
    "ohc = OneHotEncoder()\n",
    "\n",
    "# para cada coluna categórica\n",
    "for col in num_ohc_cols.index:\n",
    "    \n",
    "    # Aplique o método .fit_transform do LabelEncoder e especifique .astype(np.int)\n",
    "    # o reshape faz com que dat seja uma matriz multidimensional com uma coluna (ao invés de um vetor)\n",
    "    dat = le.fit_transform(data_ohc[col]).astype(np.int).reshape(-1,1)\n",
    "    \n",
    "    # Remova a coluna col da base de dados\n",
    "    data_ohc = data_ohc.drop(col, axis=1)\n",
    "    \n",
    "    # One hot encode the data--this returns a sparse array\n",
    "    new_dat = ohc.fit_transform(dat)\n",
    "    \n",
    "    # Vamos criar novos nomes de colunas\n",
    "    n_cols = new_dat.shape[1]\n",
    "    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n",
    "    \n",
    "    # Cria um novo dataframe a partir de new_dat e col_names, utilize o índice de data_ohc\n",
    "    new_df = pd.DataFrame(new_dat.toarray(), columns=col_names, index=data_ohc.index)\n",
    "    \n",
    "    # Concatene data_ohc com new_df\n",
    "    data_ohc = pd.concat([data_ohc, new_df], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule a diferença entre a quantidade de atributos da base original e da base nova\n",
    "data_ohc.shape[1] - data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1379, 80)\n",
      "(1379, 37)\n"
     ]
    }
   ],
   "source": [
    "#imprima as dimensões dos dados originais\n",
    "print(data.shape)\n",
    "# Remova as colunas categóricas do dataframe original\n",
    "data2 = data.drop(columns=num_ohc_cols.index)\n",
    "\n",
    "#imprima as dimensões dos dados originais, sem os atributos categóricos\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 4\n",
    "\n",
    "* Crie separações entre treino e teste para ambas as bases de dados. Para garantir a mesma divisão, use o mesmo valor para o parâmetro `random_state` em cada separação.\n",
    "* Para cada base de dados, aplique um modelo de Regressão Linear na base de treino.\n",
    "* Calcule o erro quadrático médio para a base de treino e base de teste de cada modelo. Qual modelo gera um erro menor na base de teste? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_col = 'SalePrice'\n",
    "\n",
    "# Faça a divisão da base original utilizando test_size=0.3 e random_state=42\n",
    "feature_cols = [x for x in data.columns if x != y_col]\n",
    "X_data = data[feature_cols]\n",
    "y_data = data[y_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Repita para a base data_ohc\n",
    "feature_cols_ohc = [x for x in data_ohc.columns if x != y_col]\n",
    "X_data_ohc = data_ohc[feature_cols_ohc]\n",
    "y_data_ohc = data_ohc[y_col]\n",
    "\n",
    "X_train_ohc, X_test_ohc, y_train_ohc, y_test_ohc = train_test_split(X_data_ohc, y_data_ohc, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos comparar se os índices são os mesmos, o resultado deve ser True\n",
    "(X_train_ohc.index == X_train.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'AllPub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-fa2542180939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Aplique .fit() na base de treino e predict na base de treino e teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'AllPub'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Lista para armazenar os erros das bases\n",
    "error_df = list()\n",
    "\n",
    "# Aplique .fit() na base de treino e predict na base de treino e teste\n",
    "LR = LR.fit(X_train, y_train)\n",
    "y_train_pred = LR.predict(X_train)\n",
    "y_test_pred = LR.predict(X_test)\n",
    "\n",
    "error_df.append(pd.Series({'train': mean_squared_error(y_train, y_train_pred),\n",
    "                           'test' : mean_squared_error(y_test,  y_test_pred)},\n",
    "                           name='no enc'))\n",
    "\n",
    "# Repita para a base data_ohc\n",
    "LR_ohc = LR.fit(X_train_ohc, y_train_ohc)\n",
    "y_train_pred_ohc = LR.predict(X_train_ohc)\n",
    "y_test_pred_ohc = LR.predict(X_test_ohc)\n",
    "\n",
    "error_df.append(pd.Series({'train': mean_squared_error(y_train_ohc, y_train_ohc_pred),\n",
    "                           'test' : mean_squared_error(y_test_ohc,  y_test_ohc_pred)},\n",
    "                          name='one-hot enc'))\n",
    "\n",
    "# Juntar os resultados em uma tabela\n",
    "error_df = pd.concat(error_df, axis=1)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "Note que os valores de erro na base one-hot encoded são bem diferentes para o treino e teste. Isso ocorre pois os modelos com atributos categóricos gerarm um overfit da base. Na próxima lista tentaremos tratar esse problema conforme visto em sala de aula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 5\n",
    "\n",
    "Para ambas as bases:\n",
    "\n",
    "* Escale os atributos que não são categóricos (binários) utilizando um dos seguintes modelos: `StandardScaler`, `MinMaxScaler`, `MaxAbsScaler`.\n",
    "* Aplique novamente o modelo de regressão e recalcule os erros.\n",
    "\n",
    "Não se esqueça que você deve aplicar o método `.fit_transform()` apenas na base de treino e o método `.transform()` na base de teste. Explique o porque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mute the setting wtih a copy warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'AllPub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-531c36ca2dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrainingset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_label\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' - '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscaler_label\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'scaling'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/srv/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'AllPub'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "\n",
    "scalers = {'standard': StandardScaler(),\n",
    "           'minmax': MinMaxScaler(),\n",
    "           'maxabs': MaxAbsScaler()}\n",
    "\n",
    "training_test_sets = {\n",
    "    'not_encoded': (X_train, y_train, X_test, y_test),\n",
    "    'one_hot_encoded': (X_train_ohc, y_train_ohc, X_test_ohc, y_test_ohc)}\n",
    "\n",
    "\n",
    "# Lista de colunas numéricas\n",
    "mask = X_train.dtypes == np.float\n",
    "float_columns = X_train.columns[mask]\n",
    "\n",
    "# modelo de regressão\n",
    "LR = LinearRegression()\n",
    "\n",
    "# itera sobre todas as combinações de escala e bases\n",
    "errors = {}\n",
    "for encoding_label, (_X_train, _y_train, _X_test, _y_test) in training_test_sets.items():\n",
    "    for scaler_label, scaler in scalers.items():\n",
    "        trainingset = _X_train.copy()  # vamos fazer uma cópia para não bagunçar o original\n",
    "        testset = _X_test.copy()\n",
    "        trainingset[float_columns] = scaler.fit_transform(trainingset[float_columns])\n",
    "        testset[float_columns] = scaler.transform(testset[float_columns])\n",
    "        LR.fit(trainingset, _y_train)\n",
    "        predictions = LR.predict(testset)\n",
    "        key = encoding_label + ' - ' + scaler_label + 'scaling'\n",
    "        errors[key] = mean_squared_error(_y_test, predictions)\n",
    "\n",
    "errors = pd.Series(errors)\n",
    "print(errors.to_string())\n",
    "print('-' * 80)\n",
    "for key, error_val in errors.items():\n",
    "    print(key, error_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Exercício 6\n",
    "\n",
    "Plote os valores preditos vs valores reais para um dos modelos gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e65e3503ce90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valores preditos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valores reais'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(predictions,y_test)\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('RealxPredict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
  "notebookId": 2125319687183944
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
